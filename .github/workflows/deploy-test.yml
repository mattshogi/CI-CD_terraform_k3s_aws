name: Ephemeral Deploy Test

on:
  workflow_dispatch:
    inputs:
      instance_type:
        description: EC2 instance type
        required: false
        default: t3.micro
      keep_resources:
        description: 'Keep resources after test (true/false)'
        required: false
        default: 'false'
      k3s_node_count:
        description: 'Number of agent nodes'
        required: false
        default: '0'
      environment:
        description: 'Environment tag (for resource naming)'
        required: false
        default: 'gha-test'
      readiness_attempts:
        description: 'Number of validation attempts (10s interval)'
        required: false
        default: '72'
      enable_monitoring:
        description: 'Install monitoring stack (true/false)'
        required: false
        default: 'false'
      install_docker:
        description: 'Install Docker engine (true/false)'
        required: false
        default: 'false'
      keep_on_failure:
        description: 'Do not destroy resources if apply or validation fails (for debugging)'
        required: false
        default: 'false'

concurrency:
  group: deploy-test
  cancel-in-progress: false

env:
  TF_IN_AUTOMATION: 1
  AWS_REGION: us-east-1
  TERRAFORM_CLI_ARGS: -no-color
  # HAS_SSH_KEY will be set dynamically by a step

jobs:
  deploy-validate-destroy:
    name: Provision → Validate → (Destroy)
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout
        uses: actions/checkout@v4


      - name: Detect secrets
        id: detect
        run: |
          if [ -n "${{ secrets.SSH_PRIVATE_KEY }}" ]; then echo "ssh=true" >> $GITHUB_OUTPUT; fi
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then echo "aws=true" >> $GITHUB_OUTPUT; else echo "aws=false" >> $GITHUB_OUTPUT; fi

      - name: Fail fast if AWS credentials missing
        if: steps.detect.outputs.aws != 'true'
        run: |
          echo "ERROR: AWS credentials not provided. Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY repository or environment secrets." >&2
          exit 1

      - name: Configure AWS credentials
        if: steps.detect.outputs.aws == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS identity
        if: steps.detect.outputs.aws == 'true'
        run: aws sts get-caller-identity

      - name: Prepare SSH key (optional validation via SSH)
        if: steps.detect.outputs.ssh == 'true'
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_k3s_aws
          chmod 600 ~/.ssh/id_k3s_aws
          printf "Host *\n  StrictHostKeyChecking no\n" > ~/.ssh/config

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.9.5

      - name: Terraform Init
        working-directory: infra
        run: terraform init -input=false

      - name: Terraform Plan
        id: plan
        working-directory: infra
        run: |
          terraform plan \
            -var="ssh_key_name=${{ secrets.AWS_SSH_KEY_NAME }}" \
            -var="instance_type=${{ github.event.inputs.instance_type }}" \
            -var="k3s_node_count=${{ github.event.inputs.k3s_node_count }}" \
            -var="environment=${{ github.event.inputs.environment || 'gha-test' }}" \
            -var="enable_monitoring=${{ github.event.inputs.enable_monitoring == 'true' }}" \
            -var="install_docker=${{ github.event.inputs.install_docker == 'true' }}" \
            -var="resource_name_suffix=${{ github.run_id }}" \
            -out=tfplan

      - name: Terraform Apply
        working-directory: infra
        id: apply
        run: |
          set -o pipefail
          echo "[INFO] Applying terraform plan..."
          terraform apply -auto-approve tfplan 2>&1 | tee ../terraform-apply.log
          ec=${PIPESTATUS[0]}
          echo "apply_exit_code=$ec" >> $GITHUB_OUTPUT
          if [ $ec -ne 0 ]; then
            echo "[ERROR] terraform apply failed with exit code $ec (continuing for diagnostics)" >&2
            echo "---- BEGIN terraform-apply.log (last 120 lines) immediate snippet ----" >&2
            tail -n 120 ../terraform-apply.log || true
            echo "---- END terraform-apply.log immediate snippet ----" >&2
          fi

      - name: Classify Terraform Apply Failure
        if: ${{ steps.apply.outputs.apply_exit_code != '0' }}
        id: classify
        run: |
          echo "classification=unknown" >> $GITHUB_OUTPUT
          [ -f terraform-apply.log ] || { echo "No terraform-apply.log present"; exit 0; }
          echo "---- Scanning terraform-apply.log for common transient error patterns ----"
          grep -E 'Throttling|RequestLimitExceeded|timeout|Time[out]|timed out|InternalError|ServiceUnavailable|DependencyViolation|NoSuchEntity|InvalidIAMInstanceProfile|Conflict|retryable' terraform-apply.log || true
          if grep -qiE 'Throttling|RequestLimitExceeded' terraform-apply.log; then cls=throttling; elif grep -qiE 'NoSuchEntity|InvalidIAMInstanceProfile' terraform-apply.log; then cls=iam-propagation; elif grep -qi 'DependencyViolation' terraform-apply.log; then cls=dependency-violation; elif grep -qiE 'ServiceUnavailable|InternalError' terraform-apply.log; then cls=provider-internal; else cls=unknown; fi
          echo "Detected classification: $cls"
          echo "classification=$cls" >> $GITHUB_OUTPUT

      - name: Terraform Apply Retry (transient)
        if: ${{ steps.apply.outputs.apply_exit_code != '0' && (steps.classify.outputs.classification == 'throttling' || steps.classify.outputs.classification == 'iam-propagation' || steps.classify.outputs.classification == 'provider-internal' || steps.classify.outputs.classification == 'dependency-violation') }}
        id: apply_retry
        working-directory: infra
        run: |
          echo "[INFO] Retry conditions met (classification=${{ steps.classify.outputs.classification }}). Sleeping 20s before retry..."
          sleep 20
          set -o pipefail
          terraform apply -auto-approve tfplan 2>&1 | tee -a ../terraform-apply.log
          ec=${PIPESTATUS[0]}
          echo "apply_retry_exit_code=$ec" >> $GITHUB_OUTPUT
          if [ $ec -ne 0 ]; then
            echo "[ERROR] retry terraform apply failed with exit code $ec" >&2
          else
            echo "[INFO] retry terraform apply succeeded"
          fi

      - name: Determine Final Apply Success
        id: apply_final
        run: |
          init='${{ steps.apply.outputs.apply_exit_code }}'
          retry='${{ steps.apply_retry.outputs.apply_retry_exit_code }}'
          [ -z "$init" ] && init=1
          final=failure
            if [ "$init" = "0" ]; then final=success; fi
            if [ "$retry" = "0" ]; then final=success; fi
          echo "initial_exit=$init" >> $GITHUB_OUTPUT
          echo "retry_exit=${retry:-n/a}" >> $GITHUB_OUTPUT
          echo "final=$final" >> $GITHUB_OUTPUT
          echo "Apply initial exit: $init; retry exit: ${retry:-n/a}; final=$final"

      - name: Debug Apply Outcome
        if: always()
        run: |
          echo "apply_exit_code=${{ steps.apply.outputs.apply_exit_code }}"
          echo "apply_retry_exit_code=${{ steps.apply_retry.outputs.apply_retry_exit_code || 'none' }}"
          echo "final=${{ steps.apply_final.outputs.final }}"

      - name: Evaluate Apply Success (APPLY_OK)
        id: apply_ok
        run: |
          init='${{ steps.apply.outputs.apply_exit_code }}'
          retry='${{ steps.apply_retry.outputs.apply_retry_exit_code }}'
          if [ "$init" = "0" ] || [ "$retry" = "0" ]; then ok=true; else ok=false; fi
          echo "APPLY_OK=$ok" >> $GITHUB_ENV
          echo "apply_ok=$ok" >> $GITHUB_OUTPUT
          echo "Computed APPLY_OK=$ok (init=$init retry=${retry:-n/a})"

      - name: Capture Outputs
        if: ${{ steps.apply_ok.outputs.apply_ok == 'true' }}
        id: tf-out
        working-directory: infra
        run: |
          get_out() { key=$1; name=$2; val=$(terraform output -raw "$key" 2>/dev/null || true); val=$(printf "%s" "$val" | tr -d '\r' | head -n1 | sed 's/ /_/g'); if [ -z "$val" ]; then val=UNKNOWN; fi; echo "$name=$val" >> $GITHUB_OUTPUT; }
          get_out server_public_ip server_ip
          get_out server_instance_id instance_id

      - name: Echo Terraform outputs
        if: ${{ steps.apply_ok.outputs.apply_ok == 'true' }}
        run: |
          echo "Server IP: ${{ steps.tf-out.outputs.server_ip }}"

      - name: Initial warm-up wait
        if: ${{ steps.apply_ok.outputs.apply_ok == 'true' }}
        run: |
          ip=${{ steps.tf-out.outputs.server_ip }}
          echo "Extended warm-up (120s) to allow k3s install + core pods (IP: $ip)"
          sleep 120

      - name: Poll k3s readiness via SSM
        if: ${{ steps.detect.outputs.aws == 'true' && steps.apply_ok.outputs.apply_ok == 'true' }}
        id: k3s_ready
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          if [ -z "$iid" ] || [ "$iid" = "UNKNOWN" ]; then
            echo "Instance ID unknown; skipping k3s readiness poll"; exit 0; fi
          echo "Polling k3s node list via SSM (timeout 6 min)";
          deadline=$((SECONDS+360))
          while [ $SECONDS -lt $deadline ]; do
            CMD_ID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='k3s kubectl get nodes --no-headers 2>/dev/null || true' --query 'Command.CommandId' --output text || true)
            sleep 6
            out=$(aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$iid" --query 'StandardOutputContent' --output text 2>/dev/null || true)
            echo "Attempt output: ${out}" | sed 's/\\n/ /g'
            if echo "$out" | grep -q 'Ready'; then
              echo "k3s_ready=true" >> $GITHUB_OUTPUT
              echo "k3s cluster reports Ready node"; break
            fi
            sleep 10
          done
          # Final note (can't re-read step output easily in script without context parsing)
          echo "Finished k3s readiness polling phase"

      - name: Poll k3s readiness marker (SSM)
        if: ${{ steps.detect.outputs.aws == 'true' && steps.apply_ok.outputs.apply_ok == 'true' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          if [ -z "$iid" ] || [ "$iid" = "UNKNOWN" ]; then echo "Unknown instance id; skipping marker poll"; exit 0; fi
          echo "Polling for /tmp/k3s-ready marker (timeout 6 min)"
          deadline=$((SECONDS+360))
          while [ $SECONDS -lt $deadline ]; do
            CID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='test -f /tmp/k3s-ready && echo READY || echo NOT_READY' --query 'Command.CommandId' --output text || true)
            sleep 5
            out=$(aws ssm get-command-invocation --command-id "$CID" --instance-id "$iid" --query 'StandardOutputContent' --output text 2>/dev/null || true)
            echo "Marker status: $out"
            if echo "$out" | grep -q READY; then echo "Marker detected"; exit 0; fi
            sleep 10
          done
          echo "Marker not detected within timeout"

      - name: Pre-validation service snapshot (SSM)
        if: ${{ steps.detect.outputs.aws == 'true' && steps.apply_ok.outputs.apply_ok == 'true' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          [ -z "$iid" ] && echo "No instance id for snapshot" && exit 0
          echo "Collecting pre-validation snapshot via SSM"
          CID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='echo "===== pre-validation kubectl get nodes ====="; k3s kubectl get nodes -o wide || true; echo "===== pre-validation kubectl get pods -A (top 40) ====="; k3s kubectl get pods -A -o wide 2>/dev/null | head -n 40 || true; echo "===== pre-validation kubectl get svc -A ====="; k3s kubectl get svc -A || true; echo "===== pre-validation kubectl get ingress -A ====="; k3s kubectl get ingress -A || true; echo "===== tail cloud-init-output.log (120) ====="; tail -n 120 /var/log/cloud-init-output.log || true;' --query 'Command.CommandId' --output text || true)
          sleep 6
          aws ssm get-command-invocation --command-id "$CID" --instance-id "$iid" --query 'StandardOutputContent' --output text > pre-validation-snapshot.txt 2>/dev/null || true
          echo "Pre-validation snapshot captured (size $(wc -c < pre-validation-snapshot.txt 2>/dev/null || echo 0) bytes)"

      - name: Fetch monitoring exposure log (SSM)
        if: ${{ always() && steps.detect.outputs.aws == 'true' && steps.tf-out.outputs.instance_id != '' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          [ -z "$iid" ] && echo "No instance id for monitoring log" && exit 0
          echo "Attempting to retrieve /var/log/k3s_monitoring_expose.log via SSM"
          CID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='if [ -f /var/log/k3s_monitoring_expose.log ]; then echo "===== k3s_monitoring_expose.log ====="; tail -n 400 /var/log/k3s_monitoring_expose.log; else echo "(monitoring exposure log not present)"; fi' --query 'Command.CommandId' --output text || true)
          sleep 6
          aws ssm get-command-invocation --command-id "$CID" --instance-id "$iid" --query 'StandardOutputContent' --output text > monitoring-expose.log 2>/dev/null || echo "(no monitoring log content)" > monitoring-expose.log
          echo "Monitoring exposure log captured (size $(wc -c < monitoring-expose.log 2>/dev/null || echo 0) bytes)"

      - name: Active endpoint validation (Ingress + NodePort)
        id: active_validate
        continue-on-error: true
        if: ${{ steps.apply_ok.outputs.apply_ok == 'true' }}
        run: |
          ip=${{ steps.tf-out.outputs.server_ip }}
          attempts=${{ github.event.inputs.readiness_attempts }}
          echo "Initial grace period before first validation attempt (30s)"
          sleep 30
          echo "Running scripts/validate_endpoints.sh $ip $attempts 10"
          chmod +x scripts/validate_endpoints.sh || true
          if ! scripts/validate_endpoints.sh "$ip" "$attempts" 10; then
            echo "Endpoint validation did not succeed within given attempts" >&2
            echo "validation_result=failure" >> $GITHUB_OUTPUT
          else
            echo "validation_result=success" >> $GITHUB_OUTPUT
          fi

      - name: Monitoring endpoints validation (Grafana/Prometheus)
        id: monitoring_validate
        if: ${{ steps.apply_ok.outputs.apply_ok == 'true' && github.event.inputs.enable_monitoring == 'true' }}
        continue-on-error: true
        run: |
          ip=${{ steps.tf-out.outputs.server_ip }}
          echo "Validating monitoring NodePorts on $ip (Grafana:30030 Prometheus:30900)"
          retries=40
          sleep_between=10
          success_graf=false
            success_prom=false
          stability_needed=3
          stable_graf=0; stable_prom=0
          ok_code() { code=$1; if echo "$code" | grep -qE '^(2|3)[0-9][0-9]$'; then return 0; fi; [ "$code" = "401" ] && return 0; return 1; }
          for i in $(seq 1 $retries); do
            code_graf=$(curl -s -o /dev/null -w '%{http_code}' --max-time 5 "http://$ip:30030/" || echo 000)
            code_prom=$(curl -s -o /dev/null -w '%{http_code}' --max-time 5 "http://$ip:30900/" || echo 000)
            echo "Attempt $i: Grafana=$code_graf Prometheus=$code_prom"
            if ok_code "$code_graf"; then success_graf=true; stable_graf=$((stable_graf+1)); else stable_graf=0; fi
            if ok_code "$code_prom"; then success_prom=true; stable_prom=$((stable_prom+1)); else stable_prom=0; fi
            if [ $stable_graf -ge $stability_needed ] && [ $stable_prom -ge $stability_needed ]; then
              echo "Both monitoring endpoints returned acceptable codes for $stability_needed consecutive attempts"
              break
            fi
            sleep $sleep_between
          done
          echo "grafana_ok=$success_graf" >> $GITHUB_OUTPUT
          echo "prometheus_ok=$success_prom" >> $GITHUB_OUTPUT
          if [ "$success_graf" != true ] || [ "$success_prom" != true ]; then
            echo "One or both monitoring endpoints not reachable (grafana=$success_graf prometheus=$success_prom)" >&2
            exit 1
          fi

      - name: Monitoring failure diagnostics (SSM)
        if: ${{ failure() && steps.monitoring_validate.conclusion == 'failure' && steps.detect.outputs.aws == 'true' && steps.tf-out.outputs.instance_id != '' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          echo "Collecting monitoring diagnostics via SSM for $iid"
          CMD_ID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='echo "===== monitoring namespace pods ====="; k3s kubectl get pods -n monitoring -o wide || true; echo "===== monitoring services ====="; k3s kubectl get svc -n monitoring || true; echo "===== describe grafana svc ====="; k3s kubectl describe svc kube-prometheus-stack-grafana -n monitoring || true; echo "===== describe prometheus svc ====="; k3s kubectl describe svc kube-prometheus-stack-prometheus -n monitoring || true; echo "===== recent monitoring events (tail) ====="; k3s kubectl get events -n monitoring --sort-by=.lastTimestamp | tail -n 40 || true; echo "===== monitoring expose log (tail 120) ====="; tail -n 120 /var/log/k3s_monitoring_expose.log || true;' --query 'Command.CommandId' --output text || true)
          sleep 8
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$iid" --query 'StandardOutputContent' --output text > monitoring-ssm-diagnostics.txt 2>/dev/null || echo "(no monitoring diagnostics)" > monitoring-ssm-diagnostics.txt
          echo "Monitoring diagnostics captured (size $(wc -c < monitoring-ssm-diagnostics.txt 2>/dev/null || echo 0) bytes)"

      - name: SSM in-cluster curl diagnostics (on validation failure)
        if: ${{ failure() && steps.detect.outputs.aws == 'true' && steps.apply_ok.outputs.apply_ok == 'true' && steps.active_validate.outputs.validation_result != 'success' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          [ -z "$iid" ] && echo "No instance id for SSM diagnostics" && exit 0
          echo "Running in-cluster curl diagnostics via SSM"
          CMD_ID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='echo "===== kubectl get pods -A ====="; k3s kubectl get pods -A -o wide || true; echo "===== kubectl get ingress -A ====="; k3s kubectl get ingress -A || true; echo "===== kubectl describe ingress hello-world -n hello-world ====="; k3s kubectl describe ingress hello-world -n hello-world || true; echo "===== kubectl get svc -n hello-world ====="; k3s kubectl get svc -n hello-world || true; echo "===== curl localhost NodePort (30080) ====="; curl -s -m 5 http://127.0.0.1:30080/ || true;' --query 'Command.CommandId' --output text || true)
          sleep 6
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$iid" --query 'StandardOutputContent' --output text > validation-ssm-curl.txt 2>/dev/null || true
          echo "Saved SSM curl diagnostics (size $(wc -c < validation-ssm-curl.txt 2>/dev/null || echo 0) bytes)"

      - name: Run endpoint validation script
        if: cancelled() == false
        run: |
          echo "(Secondary validation skipped: replaced by Active endpoint validation step)"
          true

      - name: Optional SSH diagnostics
        if: steps.detect.outputs.ssh == 'true'
        continue-on-error: true
        run: |
          ip=${{ steps.tf-out.outputs.server_ip }}
          echo "Collecting remote diagnostics from $ip"
          for cmd in \
            "sudo systemctl status k3s --no-pager" \
            "sudo journalctl -u k3s -n 400 --no-pager" \
            "sudo tail -n 200 /var/log/cloud-init-output.log" \
            "sudo k3s kubectl get nodes -o wide" \
            "sudo k3s kubectl get pods -A -o wide" \
            "sudo k3s kubectl get svc -A" \
            "sudo k3s kubectl get ingress -A" \
            "sudo k3s kubectl describe ingress -A || true" \
            "sudo k3s kubectl describe pods -n hello-world || true"; do
              echo "===== $cmd =====";
              ssh -i ~/.ssh/id_k3s_aws ubuntu@"$ip" "$cmd" || true;
            done > diagnostics.txt

      - name: Fetch EC2 console output
        if: always()
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          echo "Instance ID: $iid"
          if [ "$iid" = "UNKNOWN" ]; then echo "Instance ID unknown, skipping console output"; exit 0; fi
          aws ec2 get-console-output --instance-id "$iid" --latest --output text > console-output.txt 2>/dev/null || echo "(No console output yet)" > console-output.txt
          ls -l console-output.txt

      - name: SSM diagnostics (no SSH key)
        if: always() && steps.detect.outputs.aws == 'true' && steps.detect.outputs.ssh != 'true'
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          if [ "$iid" = "UNKNOWN" ]; then echo "Instance ID unknown, skipping SSM diagnostics"; exit 0; fi
          echo "Sending SSM diagnostics command to $iid"
          # Build JSON parameters for AWS-RunShellScript (array of commands executed sequentially)
          JSON_B64=$(printf '%s' '{"commands":["set -x","echo \"===== tail cloud-init-output.log (400 lines) =====\"; tail -n 400 /var/log/cloud-init-output.log 2>&1 || true","if [ -f /var/log/k3s_diagnostics_hello_world.txt ]; then echo \"===== k3s_diagnostics_hello_world.txt (200 lines) =====\"; tail -n 200 /var/log/k3s_diagnostics_hello_world.txt; fi","echo \"===== kubectl get nodes -o wide =====\"; sudo k3s kubectl get nodes -o wide 2>&1 || true","echo \"===== kubectl get pods -A -o wide =====\"; sudo k3s kubectl get pods -A -o wide 2>&1 || true","echo \"===== kubectl get svc -A =====\"; sudo k3s kubectl get svc -A 2>&1 || true","echo \"===== kubectl get ingress -A =====\"; sudo k3s kubectl get ingress -A 2>&1 || true","echo \"===== kubectl describe ingress hello-world -n hello-world =====\"; sudo k3s kubectl describe ingress hello-world -n hello-world 2>&1 || true"]}' | base64 -w0 2>/dev/null || base64)
          echo "$JSON_B64" | base64 -d > params.json 2>/dev/null || echo "$JSON_B64" | base64 --decode > params.json
          CMD_ID=$(aws ssm send-command \
            --instance-ids "$iid" \
            --document-name AWS-RunShellScript \
            --comment "Collect k3s diagnostics" \
            --parameters file://params.json \
            --query 'Command.CommandId' --output text)
          echo "Command ID: $CMD_ID"
          # Poll status
          for i in $(seq 1 30); do
            STATUS=$(aws ssm list-command-invocations --command-id "$CMD_ID" --details --query 'CommandInvocations[0].Status' --output text || echo "Unknown")
            echo "SSM command status: $STATUS"
            if [ "$STATUS" = "Success" ] || [ "$STATUS" = "Failed" ]; then break; fi
            sleep 6
          done
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$iid" --query 'StandardOutputContent' --output text > ssm-diagnostics.txt 2>/dev/null || echo "(No SSM output)" > ssm-diagnostics.txt
          echo "SSM diagnostics captured (size $(wc -c < ssm-diagnostics.txt) bytes)"

      - name: Extra cloud-init & k3s status snapshot
        if: ${{ always() && steps.detect.outputs.aws == 'true' }}
        run: |
          iid=${{ steps.tf-out.outputs.instance_id }}
          [ -z "$iid" ] && echo "No instance id for snapshot" && exit 0
          echo "Collecting additional snapshot via SSM single command"
          CID=$(aws ssm send-command --instance-ids "$iid" --document-name AWS-RunShellScript --parameters commands='echo "==== systemctl status k3s (may fail early) ===="; sudo systemctl status k3s --no-pager 2>&1 || true; echo "==== ps aux | grep k3s server ===="; ps aux | grep k3s | grep -v grep || true; echo "==== tail -n 120 /var/log/cloud-init-output.log ===="; tail -n 120 /var/log/cloud-init-output.log 2>&1 || true;' --query 'Command.CommandId' --output text || true)
          sleep 6
          aws ssm get-command-invocation --command-id "$CID" --instance-id "$iid" --query 'StandardOutputContent' --output text > extra-snapshot.txt 2>/dev/null || true
          echo "Extra snapshot captured (size $(wc -c < extra-snapshot.txt 2>/dev/null || echo 0) bytes)"

      - name: Upload diagnostics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deploy-test-diagnostics
          path: |
            infra/terraform.tfstate
            diagnostics.txt
            console-output.txt
            ssm-diagnostics.txt
            terraform-apply.log
            extra-snapshot.txt
            validation-ssm-curl.txt
            pre-validation-snapshot.txt
            monitoring-expose.log
            monitoring-ssm-diagnostics.txt
          if-no-files-found: warn

      - name: Terraform Apply Log Snippet
        if: always()
        run: |
          if [ -f terraform-apply.log ]; then
            echo "---- BEGIN terraform-apply.log (last 120 lines) ----"
            tail -n 120 terraform-apply.log || true
            echo "---- END terraform-apply.log ----"
          else
            echo "terraform-apply.log missing"
          fi
          if [ "${{ steps.classify.outputs.classification }}" != "" ]; then
            echo "Classification: ${{ steps.classify.outputs.classification }}"
          fi

      - name: Terraform Destroy (ephemeral cleanup)
        if: ${{ always() && github.event.inputs.keep_resources != 'true' && (github.event.inputs.keep_on_failure != 'true' || (steps.apply_ok.outputs.apply_ok == 'true' && steps.active_validate.outputs.validation_result == 'success')) }}
        working-directory: infra
        run: terraform destroy -auto-approve

      - name: Summary
        if: always()
        run: |
          echo "## Deploy Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "Instance IP: ${{ steps.tf-out.outputs.server_ip }}" >> $GITHUB_STEP_SUMMARY
          echo "Kept Resources: ${{ github.event.inputs.keep_resources }}" >> $GITHUB_STEP_SUMMARY
          echo "Instance Type: ${{ github.event.inputs.instance_type }}" >> $GITHUB_STEP_SUMMARY
          echo "Environment: ${{ github.event.inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "Instance ID: ${{ steps.tf-out.outputs.instance_id }}" >> $GITHUB_STEP_SUMMARY
          echo "Apply Exit Code: ${{ steps.apply.outputs.apply_exit_code }}" >> $GITHUB_STEP_SUMMARY
          echo "Retry Apply Exit Code: ${{ steps.apply_retry.outputs.apply_retry_exit_code || 'n/a' }}" >> $GITHUB_STEP_SUMMARY
          echo "Final Apply Result: ${{ steps.apply_final.outputs.final }}" >> $GITHUB_STEP_SUMMARY
          echo "APPLY_OK: ${{ steps.apply_ok.outputs.apply_ok }}" >> $GITHUB_STEP_SUMMARY
          echo "Classification: ${{ steps.classify.outputs.classification || 'n/a' }}" >> $GITHUB_STEP_SUMMARY
          echo "Validation Result: ${{ steps.active_validate.outputs.validation_result || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ github.event.inputs.enable_monitoring }}" = "true" ]; then
            echo "Grafana OK: ${{ steps.monitoring_validate.outputs.grafana_ok || 'n/a' }}" >> $GITHUB_STEP_SUMMARY
            echo "Prometheus OK: ${{ steps.monitoring_validate.outputs.prometheus_ok || 'n/a' }}" >> $GITHUB_STEP_SUMMARY
          fi
          # Determine final success based on initial or retry apply
          final_code=${{ steps.apply.outputs.apply_exit_code }}
          if [ "${{ steps.apply_retry.outputs.apply_retry_exit_code || '1' }}" = "0" ]; then final_code=0; fi
          if [ "${{ steps.apply_final.outputs.final }}" != "success" ]; then
            echo "Terraform apply (initial + retry) failed; see log artifact." >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ steps.active_validate.outputs.validation_result }}" != "success" ]; then
            echo "Validation failed (see diagnostics artifact)." >> $GITHUB_STEP_SUMMARY
          fi
          # Final outcome exit code
          if [ "${{ steps.apply_ok.outputs.apply_ok }}" != "true" ] || [ "${{ steps.active_validate.outputs.validation_result }}" != "success" ]; then
            exit 1
          fi
